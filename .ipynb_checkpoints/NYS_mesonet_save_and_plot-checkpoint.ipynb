{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created August/September 2019\n",
    "@author: masonf3\n",
    "\"\"\"\n",
    "'''NYS_mesonet_save_and_plot.py\n",
    "Make 3-day plots and save daily .csv files of key weather variables for NYS mesonet stations (126 stations in network)\n",
    "Data is read from UW Atmospheric Sciences LDM server\n",
    "Some code modified from Joe Zagrodnik's 'plot_mesowest_3day.py', used for similar task in the OLYMPEX field campaign\n",
    "\n",
    "**File Saving Information**\n",
    "CSV files, one per day, save to: '/home/disk/funnel/impacts/data_archive/nys_ground' \n",
    "3-day plots, one each time code is run, save to: '/home/disk/funnel/impacts/archive/ops/nys_ground'\n",
    "'''\n",
    "import os \n",
    "import pandas as pd \n",
    "import csv \n",
    "import time, datetime, glob \n",
    "from time import strftime \n",
    "from datetime import timedelta\n",
    "import numpy as np \n",
    "import matplotlib \n",
    "from matplotlib.dates import DayLocator, HourLocator, DateFormatter\n",
    "matplotlib.use('Agg') \n",
    "import matplotlib.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define directories\n",
    "indir = '/home/disk/data/albany/standard/*'                       #where the LDM server loads data to\n",
    "savedir = '/home/disk/bob/impacts/bin/saved'                       #folder containing pickle files \n",
    "station_info = '/home/disk/funnel/impacts/data_archive/nys_ground'        #folder containing nysm.csv (station info)\n",
    "csv_dir = '/home/disk/funnel/impacts/data_archive/nys_ground'     #save csv files here\n",
    "plot_dir = '/home/disk/funnel/impacts/archive/ops/nys_ground'     #save plots here \n",
    "#indir = '/home/disk/meso-home/masonf3/IMPACTS/standard/*'          #test - where I copied from LDM server \n",
    "#savedir = '/home/disk/meso-home/masonf3/IMPACTS/saved'             #test - folder containing pickle files\n",
    "#station_info = '/home/disk/meso-home/masonf3/IMPACTS/station_info' #test - folder containing nysm.csv (station info)\n",
    "#csv_dir = '/home/disk/meso-home/masonf3/IMPACTS/csv_test_NYS'      #test - csv directory\n",
    "#plot_dir = '/home/disk/meso-home/masonf3/IMPACTS/plot_test_NYS'    #test - plot directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vapor_pressure_calc(T,RH):\n",
    "    '''Given temperature and relative humidity, returns vapor pressure.\n",
    "    From https://www.weather.gov/media/epz/wxcalc/vaporPressure.pdf \n",
    "    \n",
    "    Parameters: \n",
    "    T (float): temperature, in degrees celsius\n",
    "    RH (float): relative humidity, in %\n",
    "                \n",
    "    Returns: \n",
    "    e (float): vapor pressure, in (find out)\n",
    "    es (float): saturation vapor pressure, in (find out)\n",
    "    '''\n",
    "    es = 6.11 * 10**((7.5*T)/(237.3+T)) #saturation vapor pressure calculation\n",
    "    e = (RH/100) * es                   #current vapor pressure calculation (using RH)\n",
    "    return e,es\n",
    "\n",
    "def Td_calc(es,RH):\n",
    "    '''Given saturation vapor pressure and relative humidity, returns dew point temperature.\n",
    "    From https://www.weather.gov/media/epz/wxcalc/vaporPressure.pdf\n",
    "    \n",
    "    Parameters: \n",
    "    es (float): saturation vapor presure, in (find out)\n",
    "    RH (float): relative humidity, in %\n",
    "\n",
    "    Returns: \n",
    "    Td (float): dew point temperature, in degrees celsius\n",
    "    '''\n",
    "    Td = (237.3*np.log((es*RH)/611))/(7.5*np.log(10)-np.log((es*RH)/611))\n",
    "    return Td\n",
    "\n",
    "def Tmv_calc(e,p,Tm):\n",
    "    '''Given current vapor pressure, station pressure, & mean 12-hour temp, returns mean 12-hour virtual temp.\n",
    "    Eq. from Ch.3 of \"Atmospheric Science, An Introductory Survey, Second Edition\" by John M. Wallace and Peter V. Hobbs\n",
    "    \n",
    "    Parameters:\n",
    "    Tm (float): mean 12-hour temp, in degrees celsius (i.e. (T_now+T_12ago)/2) \n",
    "    e (float): vapor pressure, in (find out)\n",
    "    p (float): station pressure (2m to be exact), in hPa (check this?)\n",
    "    \n",
    "    Returns:\n",
    "    Tv_bar (float): average virtual temperature, in degrees kelvin\n",
    "    '''\n",
    "    Tmv = (Tm+273.15)/(1-((e/p)*(1-0.622)))\n",
    "    return Tmv\n",
    "\n",
    "def mslp_calc(Tmv,zs,p):\n",
    "    '''Given current station elevation, station pressure, and mean 12-hour virtual temp, returns mean sea-level pressure.\n",
    "    Eq. from Ch.3 of \"Atmospheric Science, An Introductory Survey, Second Edition\" by John M. Wallace and Peter V. Hobbs\n",
    "    \n",
    "    *Note: MSLP calculations will be slightly incorrect for the very first 12 hours of data ever read by this script \n",
    "    because calculations use 12 hour average ambient temperature in their formulation. \n",
    "    \n",
    "    Parameters:\n",
    "    Tmv (float): mean 12-hour virtual temp, in degrees kelvin\n",
    "    zs (float): station elevation, in meters\n",
    "    p (float): station pressure, in hPa\n",
    "    \n",
    "    Returns:\n",
    "    p0 (float): mean sea-level pressure, in hPa (mb)\n",
    "    '''\n",
    "    g = 9.80665                          #acceleration of gravity in m*s^-2\n",
    "    Rd = 287.0                           #gas constant of dry air in J*K^-1*kg^-1\n",
    "    z = zs + 2                           #true elevation, in m (temp is taken at 2-m)\n",
    "    p0 = p*np.exp((g*(z+2))/(Rd*Tmv))\n",
    "    return p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    '''Given a filepath with timeseries of .csv files, return a dataframe containing data from the last three full days \n",
    "    to the present. Also returns a list of site station IDs in the observation network. \n",
    "    \n",
    "    Parameters: \n",
    "    path (str): filepath to directory containing observation data .csv files which are added in time.\n",
    "    \n",
    "    Returns:\n",
    "    all_data (dataframe): a dataframe of all obs data from three days ago, two days ago, yesterday, and today,\n",
    "    indexed by datetime and containing station elevation data. \n",
    "    sitelist (list): a list of site station IDs in the NYS mesonet network\n",
    "    '''\n",
    "    file_list = glob.glob(path)                                 #all files in path directory\n",
    "    file_list.sort()                                            #sort file list\n",
    "    latest_file = file_list[-1]                                 #most recent data file\n",
    "   \n",
    "    station_info_data = pd.read_csv(station_info + '/nysm.csv') #read station info from .csv file \n",
    "    station_info_data = station_info_data.set_index('stid')     #index by station id \n",
    "    \n",
    "    df = pd.read_csv(latest_file)                               #read latest weather data from NYS mesonet\n",
    "    df = df.set_index('station')                                #temporary index by station id for new data\n",
    "    for i in df.index:                                          #add elev, station full names to new data \n",
    "        df.loc[i,'station_elevation [m]'] = station_info_data.loc[i,'elevation [m]']\n",
    "        df.loc[i,'name'] = station_info_data.loc[i,'name']\n",
    "    df = df.reset_index()                                       #reset new data index\n",
    "    df['datetime'] = pd.to_datetime(df['time'],format='%Y-%m-%d %H:%M:%S UTC') #add column for datetime object\n",
    "    new_df = df.set_index('datetime')                           #set new data index to datetime \n",
    "    \n",
    "    today_pickle = new_df.index[-1].strftime('%Y%m%d')+'.pkl'\n",
    "    yesterday_pickle = (new_df.index[-1]-timedelta(days=1)).strftime('%Y%m%d')+'.pkl'\n",
    "    two_days_ago_pickle = (new_df.index[-1]-timedelta(days=2)).strftime('%Y%m%d')+'.pkl'\n",
    "    three_days_ago_pickle = (new_df.index[-1]-timedelta(days=3)).strftime('%Y%m%d')+'.pkl'\n",
    "    \n",
    "    if os.path.isfile(savedir+'/'+today_pickle):                                \n",
    "        from_file = pd.read_pickle(savedir+'/'+today_pickle)\n",
    "        today_data = from_file.append(new_df,ignore_index=False) #append latest NYS data to previous NYS data\n",
    "        today_data.to_pickle(savedir+'/'+today_pickle)\n",
    "        all_data = today_data\n",
    "        if os.path.isfile(savedir+'/'+yesterday_pickle):\n",
    "            yesterday_data = pd.read_pickle(savedir+'/'+yesterday_pickle)\n",
    "            all_data = pd.concat([today_data,yesterday_data],ignore_index=False)\n",
    "            if os.path.isfile(savedir+'/'+two_days_ago_pickle):\n",
    "                two_days_ago_data = pd.read_pickle(savedir+'/'+two_days_ago_pickle)\n",
    "                all_data = pd.concat([all_data,two_days_ago_data],ignore_index=False)\n",
    "                if os.path.isfile(savedir+'/'+three_days_ago_pickle):\n",
    "                    three_days_ago_data = pd.read_pickle(savedir+'/'+three_days_ago_pickle)\n",
    "                    all_data = pd.concat([all_data,three_days_ago_data],ignore_index=False)\n",
    "    else:\n",
    "        today_data = new_df\n",
    "        today_data.to_pickle(savedir+'/'+today_pickle)\n",
    "        all_data = today_data\n",
    "        if os.path.isfile(savedir+'/'+yesterday_pickle):\n",
    "            yesterday_data = pd.read_pickle(savedir+'/'+yesterday_pickle)\n",
    "            all_data = pd.concat([today_data,yesterday_data],ignore_index=False)\n",
    "            if os.path.isfile(savedir+'/'+two_days_ago_pickle):\n",
    "                two_days_ago_data = pd.read_pickle(savedir+'/'+two_days_ago_pickle)\n",
    "                all_data = pd.concat([all_data,two_days_ago_data],ignore_index=False)\n",
    "                if os.path.isfile(savedir+'/'+three_days_ago_pickle):\n",
    "                    three_days_ago_data = pd.read_pickle(savedir+'/'+three_days_ago_pickle)\n",
    "                    all_data = pd.concat([all_data,three_days_ago_data],ignore_index=False)\n",
    "            \n",
    "    all_data = all_data.drop_duplicates(['station','time'],keep='last')\n",
    "    all_data = all_data.sort_values(by=['station','time'],ascending=True) \n",
    "    \n",
    "    sitelist = list(df['station'].drop_duplicates())            #a list of site IDs for later use\n",
    "    \n",
    "    return all_data, sitelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_derived_data(all_data,site):\n",
    "    '''Given a dataframe of NYS weather data, calculates new dataframe columns of dew point and mean sea-level pressure.\n",
    "    \n",
    "    *Note: MSLP calculations will be slightly incorrect for the very first 12 hours of data ever read by this script \n",
    "    because calculations should use 12 hour average ambient temperature rather than observed temp in the formula*\n",
    "\n",
    "    Parameters: \n",
    "    all_data (dataframe): a dataframe of all obs data from three days ago, two days ago, yesterday, and today,\n",
    "    indexed by datetime and containing station elevation data\n",
    "    site (str): site station ID for a station in the NYS mesonet network\n",
    "    \n",
    "    Returns: \n",
    "    site_data (dataframe): pandas dataframe containing all data, both directly observed and calculated, \n",
    "    for a specific station \n",
    "    '''\n",
    "    site_data = all_data.loc[all_data['station'] == site]\n",
    "    if 'relative_humidity [percent]' and 'temp_2m [degC]' in site_data.keys():\n",
    "        e,es = vapor_pressure_calc(site_data['temp_2m [degC]'],site_data['relative_humidity [percent]']) \n",
    "        Td = Td_calc(es,site_data['relative_humidity [percent]'])  \n",
    "        site_data['dew_point_temp_2m [degC]'] = Td                          #add calculated dew point to new data  \n",
    "        if 'station_pressure [mbar]' and 'station_elevation [m]' in site_data.keys(): \n",
    "            for dt in site_data.index[:]:\n",
    "                if dt-timedelta(hours=12) in site_data.index[:]:                                          \n",
    "                    first_dt = dt-timedelta(hours=12)\n",
    "                    Tm = (site_data['temp_2m [degC]'][first_dt]+site_data['temp_2m [degC]'][dt])/2 #if 12hr+ data exists                               \n",
    "                else:                                                     \n",
    "                    Tm = site_data['temp_2m [degC]'][dt]                    #if not 12hr+ of data                  \n",
    "                Tmv =  Tmv_calc(e[dt],site_data['station_pressure [mbar]'][dt],Tm) #calc average virtual temp\n",
    "                mslp = mslp_calc(Tmv,site_data['station_elevation [m]'][dt],site_data['station_pressure [mbar]'][dt])\n",
    "                site_data.loc[dt,'mean_sea_level_pressure [mbar]'] = mslp   #add calculated mslp to data frame\n",
    "    site_data = site_data.drop_duplicates(['station','time'],keep='last')   #drop duplicate data\n",
    "    \n",
    "    return site_data                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_station_data(site_data):\n",
    "    '''Given a pandas dataframe containing all weather data for a specific station, this function saves\n",
    "    a day's worth of data into a .csv file for that station, within a folder for that day. \n",
    "    \n",
    "    Parameters:\n",
    "    site_data (dataframe): pandas dataframe containing all data, both directly observed and calculated, \n",
    "    for a specific station \n",
    "    \n",
    "    Returns: \n",
    "    None\n",
    "    \n",
    "    *Saves .csv files to csv_dir listed near top of script*\n",
    "    '''\n",
    "    latest = site_data.index[-1]\n",
    "    site = site_data['station'][0] \n",
    "    lower_site = site.lower()\n",
    "    \n",
    "    #definining dates in YYYYmmdd format (for saving and finding files)\n",
    "    yesterday_date = (latest-timedelta(hours=24)).strftime('%Y%m%d')\n",
    "    today_date = latest.strftime('%Y%m%d')\n",
    "    \n",
    "    #defining dates in YYYY-mm-dd format (for selecting ranges of data from dataframes)\n",
    "    yesterday_date_dt_format = (latest-timedelta(hours=24)).strftime('%Y-%m-%d')\n",
    "    today_date_dt_format = latest.strftime('%Y-%m-%d')\n",
    "    \n",
    "    path1_dir = csv_dir+'/'+yesterday_date\n",
    "    path0_dir = csv_dir+'/'+today_date\n",
    "    path1_file = path1_dir+'/ops.nys_ground.'+yesterday_date+'.'+lower_site+'.csv'\n",
    "    path0_file = path0_dir+'/ops.nys_ground.'+today_date+'.'+lower_site+'.csv'\n",
    "    \n",
    "    if yesterday_date in site_data.index.strftime('Y%m%d'):\n",
    "        if not os.path.exists(path1_dir):\n",
    "            os.mkdir(path1_dir)\n",
    "        if not os.path.exists(path1_file):  \n",
    "            yesterday_data = site_data[yesterday_date_dt_format]\n",
    "            yesterday_data.to_csv(path1_file)\n",
    "     \n",
    "    if not os.path.exists(path0_dir):\n",
    "        os.mkdir(path0_dir)\n",
    "    if today_date == latest.strftime('%Y%m%d'):   #assure data exists for today before making today file\n",
    "        today_data = site_data[today_date_dt_format]\n",
    "        today_data.to_csv(path0_file)\n",
    "    print('saved ' + site + ' csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_station_data(site_data):\n",
    "    '''Given a pandas dataframe containing all weather data for a specific station, this function saves a plot with\n",
    "    the last 3 days worth of weather data for that station (or as much data as available if not yet 3-days). \n",
    "    \n",
    "    Parameters:\n",
    "    site_data (dataframe): pandas dataframe containing all data, both directly observed and calculated, \n",
    "    for a specific station \n",
    "    \n",
    "    Returns:\n",
    "    None \n",
    "    \n",
    "    *saves plots to plot_dir listed near top of script*\n",
    "    '''\n",
    "    latest = site_data.index[-1]\n",
    "    site = site_data['station'][0]\n",
    "    lower_site = site.lower()\n",
    "    site_slice = site_data.loc[site_data.index >= (latest-timedelta(hours=72))] #slice data to last 72hrs\n",
    "    timestamp_end = site_slice.index[-1].strftime('%Y%m%d%H%M') #timestamp end for saving .csv files \n",
    "    dt = site_slice.index[:]                                #define dt for making subplots \n",
    "    sitetitle = site_slice['name'][0]                       #define sitetitle for fig title\n",
    "    graphtimestamp_start=dt[0].strftime(\"%m/%d/%y\")         #start date, for fig title\n",
    "    graphtimestamp=dt[-1].strftime(\"%m/%d/%y\")              #end date, for fig title\n",
    "    markersize = 1.5                                        #markersize, for subplots\n",
    "    linewidth = 1.0                                         #linewidth, for subplots\n",
    "    fig = plt.figure()                                      #create figure\n",
    "    fig.set_size_inches(10,10)                              #size figure\n",
    "    \n",
    "    if max(site_slice['snow_depth [cm]']) > 0:              #six axes if there is snow depth\n",
    "        ax1 = fig.add_subplot(6,1,1)\n",
    "        ax2 = fig.add_subplot(6,1,2,sharex=ax1)\n",
    "        ax3 = fig.add_subplot(6,1,3,sharex=ax1)\n",
    "        ax4 = fig.add_subplot(6,1,4,sharex=ax1)\n",
    "        ax5 = fig.add_subplot(6,1,5,sharex=ax1)\n",
    "        ax6 = fig.add_subplot(6,1,6,sharex=ax1)\n",
    "        ax6.set_xlabel('Time (UTC)')                        \n",
    "    else:                                                   #five axes if no snow depth\n",
    "        ax1 = fig.add_subplot(5,1,1)                            \n",
    "        ax2 = fig.add_subplot(5,1,2,sharex=ax1)\n",
    "        ax3 = fig.add_subplot(5,1,3,sharex=ax1)\n",
    "        ax4 = fig.add_subplot(5,1,4,sharex=ax1)\n",
    "        ax5 = fig.add_subplot(5,1,5,sharex=ax1)\n",
    "        ax5.set_xlabel('Time (UTC)')                        \n",
    "    \n",
    "    ax1.set_title(site+' '+sitetitle+', NY '+graphtimestamp_start+' - '+graphtimestamp) #title figure \n",
    "    #plot airT and dewT\n",
    "    if 'temp_2m [degC]' in site_slice.keys():\n",
    "        airT = site_slice['temp_2m [degC]']\n",
    "        ax1.plot_date(dt,airT,'o-',label=\"Temp\",color=\"blue\",linewidth=linewidth,markersize=markersize) \n",
    "    if 'dew_point_temp_2m [degC]' in site_slice.keys():\n",
    "        Td = site_slice['dew_point_temp_2m [degC]']\n",
    "        ax1.plot_date(dt,Td,'o-',label=\"Dew Point\",color=\"black\",linewidth=linewidth,markersize=markersize)\n",
    "    if ax1.get_ylim()[0] < 0 < ax1.get_ylim()[1]:\n",
    "        ax1.axhline(0, linestyle='-', linewidth = 1.0, color='deepskyblue')\n",
    "        trans = transforms.blended_transform_factory(ax1.get_yticklabels()[0].get_transform(), ax1.transData)\n",
    "        ax1.text(0,0,'0C', color=\"deepskyblue\", transform=trans, ha=\"right\", va=\"center\") #light blue line at 0 degrees C\n",
    "    ax1.set_ylabel('2m Temp ($^\\circ$C)')\n",
    "    ax1.legend(loc='best',ncol=2)\n",
    "    axes = [ax1]                                                #begin axes list\n",
    "\n",
    "    #plot wind speed and gust\n",
    "    if 'avg_wind_speed_merge [m/s]' in site_slice.keys():\n",
    "        wnd_spd = site_slice['avg_wind_speed_merge [m/s]'] * 1.94384 #convert to knots\n",
    "        ax2.plot_date(dt,wnd_spd,'o-',label='Speed',color=\"forestgreen\",linewidth=linewidth,markersize=markersize)\n",
    "    if 'max_wind_speed_merge [m/s]' in site_slice.keys():\n",
    "        wnd_gst = site_slice['max_wind_speed_merge [m/s]'] * 1.94384 #convert to knots\n",
    "        max_wnd_gst = wnd_gst.max(skipna=True)\n",
    "        ax2.plot_date(dt,wnd_gst,'o-',label='Gust (Max ' + str(round(max_wnd_gst,1)) + 'kt)',color=\"red\",linewidth=linewidth,markersize=markersize)\n",
    "    ax2.set_ylabel('Wind (kt)')\n",
    "    ax2.legend(loc='best',ncol=2)\n",
    "    axes.append(ax2)\n",
    "    \n",
    "    #plot wind direction\n",
    "    if 'wind_direction_merge [degree]' in site_slice.keys():\n",
    "        wnd_dir = site_slice['wind_direction_merge [degree]']\n",
    "        ax3.plot_date(dt,wnd_dir,'o-',label='Direction',color=\"purple\",linewidth=0.2, markersize=markersize)\n",
    "    ax3.set_ylim(-10,370)\n",
    "    ax3.set_ylabel('Wind Direction')\n",
    "    ax3.set_yticks([0,90,180,270,360])                          #locking y-ticks for wind direction \n",
    "    axes.append(ax3)\n",
    "    \n",
    "    #plot MSLP (or station pressure, if MSLP unavailable)\n",
    "    if 'mean_sea_level_pressure [mbar]' in site_slice.keys():\n",
    "        mslp = site_slice['mean_sea_level_pressure [mbar]']\n",
    "        min_mslp = mslp.min(skipna=True)                        #min 3-day mslp value\n",
    "        max_mslp = mslp.max(skipna=True)                        #max 3-day mslp value\n",
    "        labelname = 'Min ' + str(round(min_mslp,2)) + 'hPa, Max ' + str(round(max_mslp,2)) + 'hPa'\n",
    "        ax4.plot_date(dt,mslp,'o-',label=labelname,color='darkorange',linewidth=linewidth,markersize=markersize)\n",
    "        ax4.set_ylabel('MSLP (hPa)')\n",
    "    elif 'station_pressure [mbar]' in site_slice.keys():                                                   \n",
    "        sp = site_slice['station_pressure [mbar]']\n",
    "        min_sp = sp.min(skipna=True)                            #min 3-day station pressure value\n",
    "        max_sp = sp.max(skipna=True)                            #max 3-day station pressure value\n",
    "        labelname = 'Min ' + str(round(min_sp,2)) + 'hPa, Max ' + str(round(max_sp,2)) + 'hPa'\n",
    "        ax4.plot_date(dt,sp,'o-',label=labelname,color='darkorange',linewidth=linewidth,markersize=markersize)\n",
    "        ax4.set_ylabel('STATION Pressure (hPa)')\n",
    "        print('unable to get mslp, used station pressure instead')\n",
    "    ax4.legend(loc='best')\n",
    "    axes.append(ax4)\n",
    "\n",
    "    #plot precip accum\n",
    "    if 'precip_incremental [mm]' in site_slice.keys():\n",
    "        precip_inc = site_slice['precip_incremental [mm]']\n",
    "        precip_accum = 0.0\n",
    "        precip_accum_list = []\n",
    "        for increment in precip_inc:                            #calculate precip accumulation \n",
    "            precip_accum = precip_accum + increment\n",
    "            precip_accum_list.append(precip_accum)\n",
    "        max_precip = max(precip_accum_list)\n",
    "        labelname = 'Precip (' + str(round(max_precip,2)) + 'mm)'\n",
    "        ax5.plot_date(dt,precip_accum_list,'o-',label=labelname,color='navy',linewidth=linewidth,markersize=markersize)\n",
    "        if max_precip > 0:\n",
    "            ax5.set_ylim(-0.1*max_precip,max_precip+max_precip*0.2)\n",
    "        else:\n",
    "            ax5.set_ylim(-0.5,5)\n",
    "    ax5.legend(loc='best')\n",
    "    ax5.set_ylabel('Precip (mm)')\n",
    "    axes.append(ax5)\n",
    "    \n",
    "    #plot snow depth\n",
    "    if 'snow_depth [cm]' in site_slice.keys() and max(site_slice['snow_depth [cm]']) > 0:\n",
    "        snow_depth = site_slice['snow_depth [cm]'] * 10         #convert to mm\n",
    "        max_snow_depth = snow_depth.max(skipna=True)\n",
    "        min_snow_depth = snow_depth.min(skipna=True)\n",
    "        labelname = 'Min Depth ' + str(round(min_snow_depth,2)) + 'mm, Max Depth ' + str(round(max_snow_depth,2)) + 'mm'\n",
    "        ax6.plot_date(dt,snow_depth,'o-',label=labelname,color='deepskyblue',linewidth=linewidth,markersize=markersize)\n",
    "        ax6.set_ylim(-0.1*max_snow_depth,max_snow_depth+max_snow_depth*0.2)\n",
    "        if max_snow_depth > 0:\n",
    "            ax5.set_ylim(-0.1*max_snow_depth,max_snow_depth+max_snow_depth*0.2)\n",
    "        ax6.legend(loc='best')\n",
    "        ax6.set_ylabel('Snow Depth (mm)')\n",
    "        axes.append(ax6)\n",
    "                        \n",
    "    for ax in axes: \n",
    "        ax.spines[\"top\"].set_visible(False)                             #remove dark borders on subplots\n",
    "        ax.spines[\"right\"].set_visible(False)  \n",
    "        ax.spines[\"left\"].set_visible(False)\n",
    "        ax.spines[\"bottom\"].set_visible(False)\n",
    "        ax.tick_params(axis='x',which='both',bottom='on',top='off')     #add ticks at labeled times\n",
    "        ax.tick_params(axis='y',which='both',left='on',right='off') \n",
    "        ax.xaxis.set_major_locator( DayLocator() )                      #one date written per day\n",
    "        ax.xaxis.set_major_formatter( DateFormatter('%b-%d') )          #show date, written as 'Jul-12'\n",
    "        ax.xaxis.set_minor_locator( HourLocator(np.linspace(6,18,3)) )  #hour labels every 6 hours\n",
    "        ax.xaxis.set_minor_formatter( DateFormatter('%H') )             #show hour labels\n",
    "        ax.fmt_xdata = DateFormatter('Y%m%d%H%M%S')                     #fixes labels\n",
    "        ax.yaxis.grid(linestyle = '--')                                 #adds y-axis grid lines\n",
    "        ax.get_yaxis().set_label_coords(-0.06,0.5)                      #properly places y-labels away from figure\n",
    "    \n",
    "    #define dates in YYYYmmdd format (for saving and finding files)\n",
    "    three_days_ago_date = (latest-timedelta(hours=72)).strftime('%Y%m%d')\n",
    "    two_days_ago_date = (latest-timedelta(hours=48)).strftime('%Y%m%d')\n",
    "    yesterday_date = (latest-timedelta(hours=24)).strftime('%Y%m%d')\n",
    "    today_date = latest.strftime('%Y%m%d')\n",
    "    \n",
    "    plot_path = plot_dir+'/'+today_date\n",
    "    if not os.path.exists(plot_path):\n",
    "            os.mkdir(plot_path)\n",
    "    plt.savefig(plot_path+'/ops.nys_ground.'+timestamp_end+'.'+lower_site+'.png',bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print('plotted ' + site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading data\n",
      "Processing site = ADDI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/lib/python3/dist-packages/pandas/core/indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/usr/lib/python3/dist-packages/pandas/core/indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ADDI csv\n",
      "plotted ADDI\n",
      "Processing site = ANDE\n",
      "saved ANDE csv\n",
      "plotted ANDE\n",
      "Processing site = BATA\n",
      "saved BATA csv\n",
      "plotted BATA\n",
      "Processing site = BEAC\n",
      "saved BEAC csv\n",
      "plotted BEAC\n",
      "Processing site = BELD\n",
      "saved BELD csv\n",
      "plotted BELD\n",
      "Processing site = BELL\n",
      "saved BELL csv\n",
      "plotted BELL\n",
      "Processing site = BELM\n",
      "saved BELM csv\n",
      "plotted BELM\n",
      "Processing site = BERK\n",
      "saved BERK csv\n",
      "plotted BERK\n",
      "Processing site = BING\n",
      "saved BING csv\n",
      "plotted BING\n",
      "Processing site = BKLN\n",
      "saved BKLN csv\n",
      "plotted BKLN\n",
      "Processing site = BRAN\n",
      "saved BRAN csv\n",
      "plotted BRAN\n",
      "Processing site = BREW\n",
      "saved BREW csv\n",
      "plotted BREW\n",
      "Processing site = BROC\n",
      "saved BROC csv\n",
      "plotted BROC\n",
      "Processing site = BRON\n",
      "saved BRON csv\n",
      "plotted BRON\n",
      "Processing site = BROO\n",
      "saved BROO csv\n",
      "plotted BROO\n",
      "Processing site = BSPA\n",
      "saved BSPA csv\n",
      "plotted BSPA\n",
      "Processing site = BUFF\n",
      "saved BUFF csv\n",
      "plotted BUFF\n",
      "Processing site = BURD\n",
      "saved BURD csv\n",
      "plotted BURD\n",
      "Processing site = BURT\n",
      "saved BURT csv\n",
      "plotted BURT\n",
      "Processing site = CAMD\n",
      "saved CAMD csv\n",
      "plotted CAMD\n",
      "Processing site = CAPE\n",
      "saved CAPE csv\n",
      "plotted CAPE\n",
      "Processing site = CHAZ\n",
      "saved CHAZ csv\n",
      "plotted CHAZ\n",
      "Processing site = CHES\n",
      "saved CHES csv\n",
      "plotted CHES\n",
      "Processing site = CINC\n",
      "saved CINC csv\n",
      "plotted CINC\n",
      "Processing site = CLAR\n",
      "saved CLAR csv\n",
      "plotted CLAR\n",
      "Processing site = CLIF\n",
      "saved CLIF csv\n",
      "plotted CLIF\n",
      "Processing site = CLYM\n",
      "saved CLYM csv\n",
      "plotted CLYM\n",
      "Processing site = COBL\n",
      "saved COBL csv\n",
      "plotted COBL\n",
      "Processing site = COHO\n",
      "saved COHO csv\n",
      "plotted COHO\n",
      "Processing site = COLD\n",
      "saved COLD csv\n",
      "plotted COLD\n",
      "Processing site = COPA\n",
      "saved COPA csv\n",
      "plotted COPA\n",
      "Processing site = COPE\n",
      "saved COPE csv\n",
      "plotted COPE\n",
      "Processing site = CROG\n",
      "saved CROG csv\n",
      "plotted CROG\n",
      "Processing site = CSQR\n",
      "saved CSQR csv\n",
      "plotted CSQR\n",
      "Processing site = DELE\n",
      "saved DELE csv\n",
      "plotted DELE\n",
      "Processing site = DEPO\n",
      "saved DEPO csv\n",
      "plotted DEPO\n",
      "Processing site = DOVE\n",
      "saved DOVE csv\n",
      "plotted DOVE\n",
      "Processing site = DUAN\n",
      "saved DUAN csv\n",
      "plotted DUAN\n",
      "Processing site = EAUR\n",
      "saved EAUR csv\n",
      "plotted EAUR\n",
      "Processing site = EDIN\n",
      "saved EDIN csv\n"
     ]
    }
   ],
   "source": [
    "all_data,sitelist = load_data(indir)\n",
    "print('Done reading data')\n",
    "for site in sitelist:\n",
    "    print('Processing site = ' + site)\n",
    "    site_data = calculate_derived_data(all_data,site)\n",
    "    save = save_station_data(site_data)\n",
    "    plot = plot_station_data(site_data)\n",
    "print('All NYS Mesonet ground data plotted and saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
